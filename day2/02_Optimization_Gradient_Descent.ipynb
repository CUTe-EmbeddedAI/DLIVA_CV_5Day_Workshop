{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrbxxSaEbk2G"
      },
      "source": [
        "# Optimization and Gradient Descent\n",
        "\n",
        "Let's learn about the fundamental algorithm behind machine learning training: gradient descent.\n",
        "\n",
        "We will cover the following:\n",
        "\n",
        "- Slope: the derivative of the loss function\n",
        "\n",
        "- Computing the gradient of a loss function\n",
        "\n",
        "- Summing up the training scheme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZeuDnNMbk2U"
      },
      "source": [
        "In our 2D example, the loss function can be thought of as a parabolic-shaped function that reaches its minimum on a certain pair of $w_{1}$ and $w_{2}$. Visually, we have:\n",
        "\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig04.PNG)\n",
        "\n",
        "To find these weights, the core idea is to simply follow the slope of the curve.Although we don’t know the actual shape of the loss, we can calculate the slope in a point and then move towards the downhill direction.\n",
        "\n",
        "> You can think of the loss function as a mountain. The current loss gives us information about the local slope.\n",
        "\n",
        "But what is the slope?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXcrVxnEbk2W"
      },
      "source": [
        "# Slope: the derivative of the loss function\n",
        "\n",
        "In calculus, the slope is the derivative of the function at this point and is denoted as $\\frac{\\delta w}{\\delta x}$. The ultimate goal would be to find the global min. The minimums, local orglobal, have a nearly zero derivative, which indicates that we are located at the minimum of the curve.\n",
        "\n",
        "For now, suppose that we want to minimize the loss function $C$. By calculating the derivative, we will take small steps along the slope in an iterative fashion. In this way, we can gradually reach the minimum of the curve.\n",
        "\n",
        "The same principle can be extended into many dimensions $N$. Despite the fact this is very difficult to visualize, maths is here to help us.\n",
        "\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig05.PNG)\n",
        "\n",
        "Keep in mind that the minimum is not always the global minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "836NGuIfbk2X"
      },
      "source": [
        "# Computing the gradient of a loss function\n",
        "\n",
        "The question is how do we compute the derivative (or gradient) with respect to the weights? In simple cases, such as the two-dimensional one, we can compute the analytical form with calculus.\n",
        "\n",
        "Since our loss function is $C = (f(x_{i},W) − y_{i})^{2}$, where the classifier $f$ is $f = w_{1}x + w_{2}$, we can easily prove that:\n",
        "\n",
        "$\\frac{\\delta C}{\\delta w_{1}} = 2(w_{1}x + w_{2} - y)x$\n",
        "\n",
        "$\\frac{\\delta C}{\\delta w_{2}} = 2(w_{1}x + w_{2} - y)$\n",
        "\n",
        "This is nothing more than the partial derivatives with respect to our 2 weights. In complex cases, such as neural networks, the chain rule will come to the rescue.\n",
        "\n",
        "Now that we have our gradients, let’s adjust our weights to go downhill:\n",
        "\n",
        ">$w_{1}^\\ast = w_{1} - \\lambda \\frac{\\delta C}{\\delta w_{1}}$\n",
        "\n",
        ">$w_{2}^\\ast = w_{2} - \\lambda \\frac{\\delta C}{\\delta w_{2}}$\n",
        "\n",
        "where $\\lambda$ is a small constant called **learning rate** . The learning rate $\\lambda$ is usually between $10^{-3}$ and $10^{-6}$ and defines how quickly we move down towards thedirection of the gradient.\n",
        "\n",
        "The negative sign intuitively means that we are going downhill! We follow thenegative slope of the curve.\n",
        "\n",
        "That’s all? Yes and no.\n",
        "\n",
        "Yes, because this principle will come in handy all the time. No, because we will not calculate the derivatives for every single neural network that we will use. \n",
        "\n",
        "Don’t worry!\n",
        "\n",
        "However, we will analyze many more aspects of optimization as it is the heart ofmachine learning.\n",
        "\n",
        "Ok, we found the gradient! How do we change the parameter?\n",
        "\n",
        "This is the so-called **update rule**:\n",
        "\n",
        "> The update rule for iteration $j$ of a scalar weight $w$ is as follows:\n",
        "\n",
        "> $w_{j}^\\ast = w_{j} - \\lambda \\frac{\\delta C}{\\delta w_{j}}$\n",
        "\n",
        "> The index $j$ shows the iteration step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm8mh783bk2Z"
      },
      "source": [
        "# Summing up the training scheme\n",
        "\n",
        "To recap, the training algorithm, known as gradient descent, can be formulated like this for the N-dimensional case:\n",
        "\n",
        "- Initialize the classifier $f(x_{i} ,W)$ with random weights $W$.\n",
        "\n",
        "\n",
        "- Feed a training example $x_{i}$ (vector) with corresponding target vector $t_{i}$ in the classifier, and compute the output $y_{i} = f(x_{i} ,W)$.\n",
        "\n",
        "\n",
        "- Compute the loss between the prediction $y_{i}$ and target vector $t_{i}$. The mean squared error loss is one example that can be used $C = \\sum(y_{i} − t_{i})^2$ \n",
        "\n",
        "\n",
        "- Compute the gradients for the loss with respect to the weights/parameters.\n",
        "\n",
        "\n",
        "- Adjust the weights $W$ based on the rule $w_{i}^\\ast = w_{i} - \\lambda \\frac{\\delta C}{\\delta w_{i}}$. Note that $\\frac{\\delta C}{\\delta w_{i}}$ is the gradient of the parameter and $\\lambda$ the learning rate.\n",
        "\n",
        "\n",
        "- Repeat for all training examples.\n",
        "\n",
        "In Pytorch, the entire algorithm can again be developed with a few lines of code. In the following snippet, we have a simple linear classifier that is trained using gradient descent and the mean squared error loss. It accepts a four-sized vector and outputs a single value.\n",
        "\n",
        "Feel free to play around with the following code by trying different inputs and inspect the output and the gradient of the model. But don’t try to dive too deep into the code as we will discuss it in detail in the upcoming lessons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CAZIasA-bk2b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def train():\n",
        "    model = nn.Linear(4,2)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        # Converting inputs and labels to Variable\n",
        "        inputs = torch.Tensor([0.8,0.4,0.4,0.2])\n",
        "        labels = torch.Tensor([1,0])\n",
        "        # Clear gradient buffers because we don't want any gradient from previous epoch to\n",
        "        optimizer.zero_grad()\n",
        "        # get output from the model, given the inputs\n",
        "        outputs = model(inputs)\n",
        "        # get loss for the predicted output\n",
        "        loss = criterion(outputs, labels)\n",
        "        print(loss)\n",
        "        # get gradients w.r.t to parameters\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKlbB8DMbk2e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "02. Optimization_Gradient_Descent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}