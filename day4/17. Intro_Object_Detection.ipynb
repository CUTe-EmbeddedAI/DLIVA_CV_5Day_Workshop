{"cells":[{"cell_type":"markdown","metadata":{"id":"-0RZeN0cX3G6"},"source":["In this notebook, we will try to:\n","\n","- understand what object detection is and how it works\n","- get an overview on historical progress with different models\n","\n","### Object detection\n","\n","Object Detection is one of the most famous and extensively researched topics in the field of Machine Vision.\n","\n","To understand Object Detection in simplistic terms, it deals with identifying and localizing some of the classes such as person, car, bus, spoon, etc. from the image. This can be achieved by drawing a bounding box around the given specific target class.\n","\n","![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig37.png)\n","\n","### Object localization\n","\n","In essence, object detection is a special case of image classification that we have covered in earlier notebooks. Recall that to perform classification using neural networks, we have something like this:\n","\n","![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig38.PNG)\n","\n","where the output nodes consist of the target classes that we want to predict.\n","\n","In object localization, however, we add another 4 output nodes to predict another 4 values to define a bounding box!\n","\n","![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig39.PNG)\n","\n","There are two common ways to define the bounding box (BBOX):\n","\n","- (x1,y1) is the upper left corner point, (x2,y2) is bottom right corner point.\n","- two points to define a corner point, two points to define the height and the width of the bbox. \n","\n","Therefore, in a neural network for object detection, it is common to have a classification loss (e.g. cross entry loss) to predict the classes (cat vs dog) and a regression loss (e.g. L2 norm/ MAE) to predict the floating values of the bbox.\n","\n","But, one question, how do we generalize for multiple object detection? Here comes some of the proposed methods in literature over the years.\n","\n","### Sliding windows: the \"natural\" extension\n","\n","![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig40.gif)\n","\n","The idea is to slide a lot of \"windows\" as patches (with some stride, different sizes of windows) and try to classify the extracted patches using CNN.\n","\n","Potential problems? \n","\n","- It is extremely computational expensive!\n","- Many bounding boxes for the same object.\n","\n","Examples in this category are R-CNN, fast R-CNN, faster R-CNN.\n","\n","![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig41.PNG)\n","\n","### You Only Look Once (YOLO)\n","\n","Fortunately, these steps are skipped in single-shot detectors. As these detectors do not depend on the region proposals, it predicts the limited fixed amount of proposals at a given time from an image and directly undergoes global regression/classification, mapping straightly from image pixels to bounding box coordinates and class probabilities. \n","\n","In general, single-stage detectors tend to be less accurate than two-stage detectors but are significantly faster.\n","\n","![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig42.PNG)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rfk9DlrsX3HB"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3.7 (pytorch_hasan)","language":"python","name":"torch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"17. Intro_Object_Detection.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}