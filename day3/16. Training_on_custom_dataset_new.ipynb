{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2938,
     "status": "ok",
     "timestamp": 1658119859749,
     "user": {
      "displayName": "احمد اسعد",
      "userId": "15464471792373836994"
     },
     "user_tz": -480
    },
    "id": "gu5EoMTZpGPe"
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rokxI_qOpGPk"
   },
   "source": [
    "## Structure of our data folder\n",
    "\n",
    "For this exercise, we’ll keep the following folder structure:\n",
    "\n",
    "<div> <img src=\"images/fig47.png\" alt=\"Drawing\" style=\"width: 300px;\"/></div> \n",
    "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig47.png)\n",
    "\n",
    "This is a straightforward folder structure with a root folder as the Train/Test folders containing classes with images inside them. \n",
    "\n",
    "*However, some other dataset, as you’ll see in the future, might have a slightly different structure. It doesn’t matter in what structure we get the data in. The data can all be in a single folder with class names in the image names (like “Cat_001.jpg”) or even in a CSV, we can process all this in our custom dataset class.\n",
    "\n",
    "Let's apply some transformations to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1658119900978,
     "user": {
      "displayName": "احمد اسعد",
      "userId": "15464471792373836994"
     },
     "user_tz": -480
    },
    "id": "Veui89ripGPp"
   },
   "outputs": [],
   "source": [
    "# Applying Transforms to the Data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoUb9dAOpGPq"
   },
   "source": [
    "## Method 1: Define dataset using `torchvision.datasets.ImageFolder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 1494,
     "status": "error",
     "timestamp": 1658119905303,
     "user": {
      "displayName": "احمد اسعد",
      "userId": "15464471792373836994"
     },
     "user_tz": -480
    },
    "id": "sGWbs8c-pGPr",
    "outputId": "cd55e47c-3ef5-4947-9dd9-0e5b5cc2f27b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "\n",
    "# Set train and valid directory paths\n",
    "\n",
    "# dataset = '/content/drive/My Drive/01. TEACHING/MACHINE_VISION/code/fruit_dataset'\n",
    "dataset = './fruit_dataset'\n",
    "\n",
    "train_directory = os.path.join(dataset, 'train')\n",
    "test_directory = os.path.join(dataset, 'validation')\n",
    "\n",
    "# Batch size\n",
    "batchSize = 32\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(train_directory))\n",
    "print(num_classes)\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "\n",
    "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "# idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "# print(idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JAEEe58pGPs"
   },
   "source": [
    "Let's see the info on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "error",
     "timestamp": 1658119931916,
     "user": {
      "displayName": "احمد اسعد",
      "userId": "15464471792373836994"
     },
     "user_tz": -480
    },
    "id": "L4m0JrIXpGPt",
    "outputId": "b2a0d304-f068-4054-9e40-f1e1c406c4ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 600\n",
       "    Root location: ./fruit_dataset\\train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "               RandomRotation(degrees=[-15.0, 15.0], resample=False, expand=False)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               CenterCrop(size=(224, 224))\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JuZoH8SVpGPu"
   },
   "outputs": [],
   "source": [
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "# valid_data_size = len(data['valid'])\n",
    "test_data_size = len(data['test'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=batchSize, shuffle=True)\n",
    "# valid_data_loader = DataLoader(data['valid'], batch_size=batchSize, shuffle=True)\n",
    "test_data_loader = DataLoader(data['test'], batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lllGMRytpGPv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 150)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_size, test_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7pHq9YTbpGPw"
   },
   "outputs": [],
   "source": [
    "input_size = (3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jTuCiNMepGPx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#                  Create Dataloader                     #\n",
    "#######################################################\n",
    "\n",
    "# Turn train and test custom Dataset's into DataLoader's\n",
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(dataset=data['train'], # use custom created train Dataset\n",
    "                                     batch_size=4, # how many samples per batch?\n",
    "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
    "                                     shuffle=True) # shuffle the data?\n",
    "\n",
    "testloader = DataLoader(dataset=data['test'], # use custom created test Dataset\n",
    "                                    batch_size=4, \n",
    "                                    num_workers=0, \n",
    "                                    shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_data_size = len(trainloader.dataset)\n",
    "test_data_size = len(testloader.dataset)\n",
    "\n",
    "print(train_data_size)\n",
    "print(test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z7TYXzQ4pGPy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################\n",
    "# DEFINE YOUR OWN MODEL\n",
    "#######################\n",
    "\n",
    "# 2. LOSS AND OPTIMIZER\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)\n",
    "\n",
    "# 3. move the model to GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bEVE8du9pGPz"
   },
   "outputs": [],
   "source": [
    "import time # to calculate training time\n",
    "\n",
    "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(testloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_test_loss = valid_loss/test_data_size \n",
    "        avg_test_acc = valid_acc/test_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save if the model has best accuracy till now\n",
    "        torch.save(model, 'cifar10_model_'+str(epoch)+'.pt')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k9tt7xW0pGP0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n",
      "Epoch : 000, Training: Loss: 2.0994, Accuracy: 29.0000%, \n",
      "\t\tValidation : Loss : 1.6089, Accuracy: 40.6667%, Time: 10.4596s\n",
      "Epoch: 2/10\n",
      "Epoch : 001, Training: Loss: 1.3679, Accuracy: 49.6667%, \n",
      "\t\tValidation : Loss : 1.2155, Accuracy: 52.6667%, Time: 5.2751s\n",
      "Epoch: 3/10\n",
      "Epoch : 002, Training: Loss: 1.1328, Accuracy: 59.1667%, \n",
      "\t\tValidation : Loss : 0.9990, Accuracy: 68.6667%, Time: 5.2542s\n",
      "Epoch: 4/10\n",
      "Epoch : 003, Training: Loss: 0.9704, Accuracy: 70.6667%, \n",
      "\t\tValidation : Loss : 0.8511, Accuracy: 74.6667%, Time: 5.2597s\n",
      "Epoch: 5/10\n",
      "Epoch : 004, Training: Loss: 0.8939, Accuracy: 71.8333%, \n",
      "\t\tValidation : Loss : 0.7589, Accuracy: 78.6667%, Time: 5.2755s\n",
      "Epoch: 6/10\n",
      "Epoch : 005, Training: Loss: 0.7804, Accuracy: 78.5000%, \n",
      "\t\tValidation : Loss : 0.6697, Accuracy: 80.6667%, Time: 5.3780s\n",
      "Epoch: 7/10\n",
      "Epoch : 006, Training: Loss: 0.7416, Accuracy: 78.6667%, \n",
      "\t\tValidation : Loss : 0.5935, Accuracy: 84.6667%, Time: 5.3195s\n",
      "Epoch: 8/10\n",
      "Epoch : 007, Training: Loss: 0.7052, Accuracy: 80.3333%, \n",
      "\t\tValidation : Loss : 0.5357, Accuracy: 86.0000%, Time: 5.2668s\n",
      "Epoch: 9/10\n",
      "Epoch : 008, Training: Loss: 0.6629, Accuracy: 79.6667%, \n",
      "\t\tValidation : Loss : 0.4623, Accuracy: 91.3333%, Time: 5.3432s\n",
      "Epoch: 10/10\n",
      "Epoch : 009, Training: Loss: 0.6291, Accuracy: 80.1667%, \n",
      "\t\tValidation : Loss : 0.4443, Accuracy: 90.0000%, Time: 5.3622s\n"
     ]
    }
   ],
   "source": [
    "# 4. Train the model for 10 epochs\n",
    " \n",
    "num_epochs = 10\n",
    "trained_model, history = train_and_validate(model, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Analyze the loss curve\n",
    "\n",
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,3)\n",
    "# plt.savefig('cifar10_loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Analyze the accuracy curve\n",
    "\n",
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "# plt.savefig('cifar10_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyBTMMjIpGP1"
   },
   "source": [
    "## Method 2: Define custom dataset in Pytorch\n",
    "\n",
    "Pytorch has a great ecosystem to load custom datasets for training machine learning models.\n",
    "\n",
    "This is a straightforward folder structure with a root folder as the Train/Test folders containing classes with images inside them. As we’ll see, it doesn’t matter in what structure we get the data in. The data can all be in a single folder with class names in the image names (like “Cat_001.jpg”) or even in a CSV, we can process all this in our custom dataset class.\n",
    "\n",
    "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig47.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yD2vu2-BpGP2"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import numpy\n",
    "import random\n",
    "from pandas.core.common import flatten\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YlBTvIC7pGP2"
   },
   "outputs": [],
   "source": [
    "# Applying Transforms to the Data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbPvryT3pGP3"
   },
   "source": [
    "Next, we create the Train, Valid, and Test sets. Here we create separate lists of image paths for Train, Valid, and Test sets. These will be used in our Dataset class which will be defined for a custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "4QyD3_gspGP3",
    "outputId": "b350d1a3-d360-45af-9e79-94ded43ee2fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image_path example:  fruit_dataset/train\\tomato\\59393810f0d0e200b9f5333661b10edaaa3580a4.jpg\n",
      "class example:  pumpkin\n",
      "Train size: 600\n",
      "Test size: 150\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#       Create Train, Valid and Test sets\n",
    "####################################################\n",
    "train_data_path = 'fruit_dataset/train' \n",
    "test_data_path = 'fruit_dataset/validation'\n",
    "\n",
    "train_image_paths = [] #to store image paths in list\n",
    "classes = [] #to store class values\n",
    "\n",
    "#1.\n",
    "# get all the paths from train_data_path and append image paths and class to to respective lists\n",
    "\n",
    "for data_path in glob.glob(train_data_path + '/*'):\n",
    "    classes.append(data_path.split('\\\\')[-1]) \n",
    "    train_image_paths.append(glob.glob(data_path + '/*'))\n",
    "    \n",
    "train_image_paths = list(flatten(train_image_paths))\n",
    "random.shuffle(train_image_paths)\n",
    "\n",
    "print('train_image_path example: ', train_image_paths[0])\n",
    "print('class example: ', classes[0])\n",
    "\n",
    "#2.\n",
    "# create the test_image_paths\n",
    "test_image_paths = []\n",
    "for data_path in glob.glob(test_data_path + '/*'):\n",
    "    test_image_paths.append(glob.glob(data_path + '/*'))\n",
    "\n",
    "test_image_paths = list(flatten(test_image_paths))\n",
    "\n",
    "print(\"Train size: {}\\nTest size: {}\".format(len(train_image_paths), len(test_image_paths)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WnFBuLIpGP5"
   },
   "source": [
    "We can’t use the class names directly for models. We create mappings of classes to index and index to classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2pWX-w_OpGP5",
    "outputId": "5d4faa2f-738c-4d02-eb7c-68b41863c34b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pumpkin': 0, 'tomato': 1, 'watermelon': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################\n",
    "#      Create dictionary for class indexes\n",
    "#######################################################\n",
    "\n",
    "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ieQ94EppGP6"
   },
   "source": [
    "### Create Dataset Class\n",
    "\n",
    "This is the core of our custom dataset. The structure of the dataset class is something like this:\n",
    "\n",
    "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig48.png) \n",
    "\n",
    "We create our customDataset class by inheriting the Dataset class:\n",
    "\n",
    ">from torch.utils.data import Dataset\n",
    "\n",
    "First, we define the **init** function. As soon as we create an instance of our customDataset class, this function is called by default. This function should contain all operations that we want to run on the whole dataset (eg. train) once. For now, we define the variables for image_paths and transforms for the corresponding Train and Test sets.\n",
    "\n",
    "Then we have the **len** function which just returns the length of the dataset. This is used afterward by the DataLoader to create batches.\n",
    "\n",
    "And finally, we have **getitem**. This processes and returns 1 datapoint at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YIA3jjz8pGP6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "#######################################################\n",
    "#               Define Dataset Class\n",
    "#######################################################\n",
    "\n",
    "class fruitDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "#         image = cv2.imread(image_filepath)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.open(image_filepath) # if using torchvision transforms\n",
    "        \n",
    "        label = image_filepath.split('\\\\')[-2]\n",
    "        label = class_to_idx[label]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image) # if using torchvision transforms\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US85U4HbpGP7"
   },
   "source": [
    "As can be seen above, __getitem__ expects an index. This is handled automatically by the dataloader which for every image in the batch runs __getitem__. In the code for __getitem__, we load the image at index “idx”, extract the label from the file path and then run it through our defined transform. The function returns the Tensor of the image array and its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KwzBKz3jpGP7"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                  Create Dataset\n",
    "#######################################################\n",
    "\n",
    "train_dataset = fruitDataset(train_image_paths,image_transforms['train'])\n",
    "test_dataset = fruitDataset(test_image_paths,image_transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "    RandomRotation(degrees=[-15.0, 15.0], resample=False, expand=False)\n",
       "    RandomHorizontalFlip(p=0.5)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfUCDyO1pGP7"
   },
   "source": [
    "After creating the train_dataset, we can access one example as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JqZzTGeRpGP8",
    "outputId": "3a2a6bb5-bc9c-42c8-8263-558f4d358692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of tensor for 50th image in train dataset:  torch.Size([3, 224, 224])\n",
      "The label for 50th image in train dataset:  1\n"
     ]
    }
   ],
   "source": [
    "print('The shape of tensor for 50th image in train dataset: ',train_dataset[49][0].shape)\n",
    "print('The label for 50th image in train dataset: ',train_dataset[49][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qApD_A6TpGP9"
   },
   "source": [
    "The final step. DataLoader class is used to load data in batches for the model. This helps us processing data in mini-batches that can fit within our GPU’s RAM. First, we import the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "10uAPyqbpGP9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1czDr28pGP9"
   },
   "source": [
    "Initiating the dataloader by sending in an object of the dataset and the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "G_rTsHDupGP-",
    "outputId": "4251cf19-9983-45d3-ec44-c0e1f725db4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#                  Create Dataloader                     #\n",
    "#######################################################\n",
    "\n",
    "# Turn train and test custom Dataset's into DataLoader's\n",
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(dataset=train_dataset, # use custom created train Dataset\n",
    "                                     batch_size=4, # how many samples per batch?\n",
    "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
    "                                     shuffle=True) # shuffle the data?\n",
    "\n",
    "testloader = DataLoader(dataset=test_dataset, # use custom created test Dataset\n",
    "                                    batch_size=4, \n",
    "                                    num_workers=0, \n",
    "                                    shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_data_size = len(trainloader.dataset)\n",
    "test_data_size = len(testloader.dataset)\n",
    "\n",
    "print(train_data_size)\n",
    "print(test_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxnuI5HcpGP-"
   },
   "source": [
    "Once we have the dataloader instance — trainloader, we can use an iterator to access the data like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "0_HtQrflpGP-",
    "outputId": "008cbee5-1e8c-478c-b2a8-b4bc6e409244"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 224, 224])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch of image tensor\n",
    "next(iter(trainloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "wtNMfI8EpGP_",
    "outputId": "4d785669-314a-4508-fcca-b1c24a3ce733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch of the corresponding labels\n",
    "next(iter(trainloader))[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBhTZjI7pGQA"
   },
   "source": [
    "This is what we use to batch out the data in our training loop. Every time we run the iterator, the dataloader selects the next 64 indexes and runs it through the __getitem__ in dataset class one by one and then returns it to the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Mx0Es2OmpGQA",
    "outputId": "9c6dc0aa-8b81-4363-b491-207d6db616c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# 2. LOSS AND OPTIMIZER\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)\n",
    "\n",
    "# 3. move the model to GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Hj9UqJUapGQA"
   },
   "outputs": [],
   "source": [
    "import time # to calculate training time\n",
    "\n",
    "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(testloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_test_loss = valid_loss/test_data_size \n",
    "        avg_test_acc = valid_acc/test_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save if the model has best accuracy till now\n",
    "        torch.save(model, 'cifar10_model_'+str(epoch)+'.pt')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1yQmzyDZpGQB",
    "outputId": "626c83e2-ecc8-459a-9677-ec5137b96848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n",
      "Epoch : 000, Training: Loss: 2.1089, Accuracy: 21.8333%, \n",
      "\t\tValidation : Loss : 1.5176, Accuracy: 41.3333%, Time: 8.1628s\n",
      "Epoch: 2/10\n",
      "Epoch : 001, Training: Loss: 1.3680, Accuracy: 45.6667%, \n",
      "\t\tValidation : Loss : 1.0533, Accuracy: 62.0000%, Time: 5.2228s\n",
      "Epoch: 3/10\n",
      "Epoch : 002, Training: Loss: 1.1057, Accuracy: 62.0000%, \n",
      "\t\tValidation : Loss : 0.8540, Accuracy: 72.0000%, Time: 5.2462s\n",
      "Epoch: 4/10\n",
      "Epoch : 003, Training: Loss: 0.9720, Accuracy: 68.6667%, \n",
      "\t\tValidation : Loss : 0.7272, Accuracy: 83.3333%, Time: 5.2742s\n",
      "Epoch: 5/10\n",
      "Epoch : 004, Training: Loss: 0.8472, Accuracy: 76.8333%, \n",
      "\t\tValidation : Loss : 0.6008, Accuracy: 91.3333%, Time: 5.2742s\n",
      "Epoch: 6/10\n",
      "Epoch : 005, Training: Loss: 0.7922, Accuracy: 77.8333%, \n",
      "\t\tValidation : Loss : 0.5096, Accuracy: 93.3333%, Time: 5.2431s\n",
      "Epoch: 7/10\n",
      "Epoch : 006, Training: Loss: 0.7161, Accuracy: 81.6667%, \n",
      "\t\tValidation : Loss : 0.4711, Accuracy: 93.3333%, Time: 5.2592s\n",
      "Epoch: 8/10\n",
      "Epoch : 007, Training: Loss: 0.6939, Accuracy: 78.0000%, \n",
      "\t\tValidation : Loss : 0.4397, Accuracy: 94.0000%, Time: 5.2664s\n",
      "Epoch: 9/10\n",
      "Epoch : 008, Training: Loss: 0.6507, Accuracy: 81.0000%, \n",
      "\t\tValidation : Loss : 0.3985, Accuracy: 92.0000%, Time: 5.2642s\n",
      "Epoch: 10/10\n",
      "Epoch : 009, Training: Loss: 0.6193, Accuracy: 81.5000%, \n",
      "\t\tValidation : Loss : 0.3474, Accuracy: 98.0000%, Time: 5.2582s\n"
     ]
    }
   ],
   "source": [
    "# 4. Train the model for 10 epochs\n",
    " \n",
    "num_epochs = 10\n",
    "trained_model, history = train_and_validate(model, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "90blSVXopGQC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Analyze the loss curve\n",
    "\n",
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,3)\n",
    "# plt.savefig('cifar10_loss_curve.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. Analyze the accuracy curve\n",
    "\n",
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "# plt.savefig('cifar10_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from IPython.display import display, Javascript, Image\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode, b64encode\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time\n",
    "\n",
    "\n",
    "# function to convert the JavaScript object into an OpenCV image\n",
    "def js_to_image(js_reply):\n",
    "  \"\"\"\n",
    "  Params:\n",
    "          js_reply: JavaScript object containing image from webcam\n",
    "  Returns:\n",
    "          img: OpenCV BGR image\n",
    "  \"\"\"\n",
    "  # decode base64 image\n",
    "  image_bytes = b64decode(js_reply.split(',')[1])\n",
    "  # convert bytes to numpy array\n",
    "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "  # decode numpy array into OpenCV BGR image\n",
    "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
    "\n",
    "  return img\n",
    "\n",
    "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
    "def bbox_to_bytes(bbox_array):\n",
    "  \"\"\"\n",
    "  Params:\n",
    "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
    "  Returns:\n",
    "        bytes: Base64 image byte string\n",
    "  \"\"\"\n",
    "  # convert array into PIL image\n",
    "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
    "  iobuf = io.BytesIO()\n",
    "  # format bbox into png for return\n",
    "  bbox_PIL.save(iobuf, format='png')\n",
    "  # format return string\n",
    "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
    "\n",
    "  return bbox_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JavaScript to properly create our live video stream using our webcam as input\n",
    "def video_stream():\n",
    "  js = Javascript('''\n",
    "    var video;\n",
    "    var div = null;\n",
    "    var stream;\n",
    "    var captureCanvas;\n",
    "    var imgElement;\n",
    "    var labelElement;\n",
    "    \n",
    "    var pendingResolve = null;\n",
    "    var shutdown = false;\n",
    "    \n",
    "    function removeDom() {\n",
    "       stream.getVideoTracks()[0].stop();\n",
    "       video.remove();\n",
    "       div.remove();\n",
    "       video = null;\n",
    "       div = null;\n",
    "       stream = null;\n",
    "       imgElement = null;\n",
    "       captureCanvas = null;\n",
    "       labelElement = null;\n",
    "    }\n",
    "    \n",
    "    function onAnimationFrame() {\n",
    "      if (!shutdown) {\n",
    "        window.requestAnimationFrame(onAnimationFrame);\n",
    "      }\n",
    "      if (pendingResolve) {\n",
    "        var result = \"\";\n",
    "        if (!shutdown) {\n",
    "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
    "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
    "        }\n",
    "        var lp = pendingResolve;\n",
    "        pendingResolve = null;\n",
    "        lp(result);\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    async function createDom() {\n",
    "      if (div !== null) {\n",
    "        return stream;\n",
    "      }\n",
    "\n",
    "      div = document.createElement('div');\n",
    "      div.style.border = '2px solid black';\n",
    "      div.style.padding = '3px';\n",
    "      div.style.width = '100%';\n",
    "      div.style.maxWidth = '600px';\n",
    "      document.body.appendChild(div);\n",
    "      \n",
    "      const modelOut = document.createElement('div');\n",
    "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
    "      labelElement = document.createElement('span');\n",
    "      labelElement.innerText = 'No data';\n",
    "      labelElement.style.fontWeight = 'bold';\n",
    "      modelOut.appendChild(labelElement);\n",
    "      div.appendChild(modelOut);\n",
    "           \n",
    "      video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      video.width = div.clientWidth - 6;\n",
    "      video.setAttribute('playsinline', '');\n",
    "      video.onclick = () => { shutdown = true; };\n",
    "      stream = await navigator.mediaDevices.getUserMedia(\n",
    "          {video: { facingMode: \"environment\"}});\n",
    "      div.appendChild(video);\n",
    "\n",
    "      imgElement = document.createElement('img');\n",
    "      imgElement.style.position = 'absolute';\n",
    "      imgElement.style.zIndex = 1;\n",
    "      imgElement.onclick = () => { shutdown = true; };\n",
    "      div.appendChild(imgElement);\n",
    "      \n",
    "      const instruction = document.createElement('div');\n",
    "      instruction.innerHTML = \n",
    "          '<span style=\"color: red; font-weight: bold;\">' +\n",
    "          'When finished, click here or on the video to stop this demo</span>';\n",
    "      div.appendChild(instruction);\n",
    "      instruction.onclick = () => { shutdown = true; };\n",
    "      \n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      captureCanvas = document.createElement('canvas');\n",
    "      captureCanvas.width = 640; //video.videoWidth;\n",
    "      captureCanvas.height = 480; //video.videoHeight;\n",
    "      window.requestAnimationFrame(onAnimationFrame);\n",
    "      \n",
    "      return stream;\n",
    "    }\n",
    "    async function stream_frame(label, imgData) {\n",
    "      if (shutdown) {\n",
    "        removeDom();\n",
    "        shutdown = false;\n",
    "        return '';\n",
    "      }\n",
    "\n",
    "      var preCreate = Date.now();\n",
    "      stream = await createDom();\n",
    "      \n",
    "      var preShow = Date.now();\n",
    "      if (label != \"\") {\n",
    "        labelElement.innerHTML = label;\n",
    "      }\n",
    "            \n",
    "      if (imgData != \"\") {\n",
    "        var videoRect = video.getClientRects()[0];\n",
    "        imgElement.style.top = videoRect.top + \"px\";\n",
    "        imgElement.style.left = videoRect.left + \"px\";\n",
    "        imgElement.style.width = videoRect.width + \"px\";\n",
    "        imgElement.style.height = videoRect.height + \"px\";\n",
    "        imgElement.src = imgData;\n",
    "      }\n",
    "      \n",
    "      var preCapture = Date.now();\n",
    "      var result = await new Promise(function(resolve, reject) {\n",
    "        pendingResolve = resolve;\n",
    "      });\n",
    "      shutdown = false;\n",
    "      \n",
    "      return {'create': preShow - preCreate, \n",
    "              'show': preCapture - preShow, \n",
    "              'capture': Date.now() - preCapture,\n",
    "              'img': result};\n",
    "    }\n",
    "    ''')\n",
    "\n",
    "  display(js)\n",
    "  \n",
    "def video_frame(label, bbox):\n",
    "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start streaming video from webcam\n",
    "video_stream()\n",
    "# label for video\n",
    "label_html = 'Capturing...'\n",
    "# initialze bounding box to empty\n",
    "bbox = ''\n",
    "count = 0 \n",
    "while True:\n",
    "    js_reply = video_frame(label_html, bbox)\n",
    "    if not js_reply:\n",
    "        break\n",
    "\n",
    "    # convert JS response to OpenCV Image\n",
    "    frame = js_to_image(js_reply[\"img\"])\n",
    "\n",
    "    #     rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Apply transforms to the input image.\n",
    "    input_tensor = transform(frame)\n",
    "    # Add the batch dimension.\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    input_batch = input_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        output = model(input_batch)\n",
    "        end_time = time.time()\n",
    "    # Get the softmax probabilities.\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    # Check the top 5 categories that are predicted.\n",
    "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "    \n",
    "    cv2.putText(frame, f\"{top5_prob[0].item()*100:.3f}%\", (15, (1)*30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, f\"{categories[top5_catid[0]]}\", (160, (1)*30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    print(categories[top5_catid[0]], top5_prob[0].item())\n",
    "    cv2_imshow(frame)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "16. Training_on_custom_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch_hasan)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
